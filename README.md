# ConUHacks2024

The #### is a project aimed at enhancing accessibility by introducing a virtual mouse that is controlled by a webcam or a voice command functionality for actions and screen navigation using a grid-based system. Leveraging the power of computer vision, the project utilizes OpenCV and MediaPipe for hand-tracking, enabling users to control the virtual mouse through hand gestures. Additionally, voice commands are supported through the integration of SpeechRecognition and PyAudio.

## Key Dependencies
- opencv-python
- mediapipe
- pyautogui
- speechrecognition
- pyaudio
- pynput

This project empowers users with diverse needs to interact with computers more effectively, making digital environments more inclusive and user-friendly.
